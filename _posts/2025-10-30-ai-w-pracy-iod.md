---
title: AI w pracy Inspektora Ochrony Danych – Jak wykorzystać sztuczną inteligencję bez naruszenia RODO?
date: 2025-10-30T11:34:13.27Z
categories:
  - Sztuczna inteligencja
tags:
  - Analiza ryzyka
  - LLM
  - AI
  - Anonimizacja
description: Inspektor Ochrony Danych stoi przed unikalnym wyzwaniem - z jednej strony musi zapewnić najwyższą ochronę danych osobowych w organizacji, z drugiej – efektywnie zarządzać coraz większą liczbą zadań i obowiązków. Sztuczna inteligencja, a konkretnie duże modele językowe (LLM), mogą znacząco usprawnić codzienną pracę IOD, ale tylko pod warunkiem, że będą wykorzystywane w sposób zgodny z RODO i zasadami bezpieczeństwa danych.
---

## Dlaczego komercyjne rozwiązania AI są ryzykowne dla IOD?

### Status IOD jako podmiotu przetwarzającego

IOD w swojej codziennej pracy przetwarza szczególnie wrażliwe dane osobowe – od umów powierzenia, przez klauzule informacyjne, po rejestry czynności przetwarzania zawierające informacje o procesach biznesowych organizacji. Zgodnie z RODO, gdy IOD wykonuje swoje zadania na podstawie umowy o świadczenie usług (co jest częstą praktyką), występuje w roli **podmiotu przetwarzającego (procesora)**.

### Ryzyko wycieku danych przy korzystaniu z komercyjnych narzędzi

Popularne narzędzia AI takie jak ChatGPT, Claude czy Gemini, mimo że oferują zaawansowane możliwości, niosą ze sobą istotne zagrożenia dla IOD. Po pierwsze, wszystkie zapytania trafiają na serwery firm trzecich (OpenAI, Anthropic, Google), co oznacza **przesyłanie danych do serwerów zewnętrznych**; po drugie, użytkownik traci kontrolę nad tym, jak dane są wykorzystywane, przechowywane czy potencjalnie wykorzystywane do trenowania modeli; po trzecie, wprowadzenie danych objętych umową powierzenia do zewnętrznych systemów AI może być uznane za **naruszenie umów powierzenia** i nieuprawnione przekazanie danych; po czwarte, transfer danych osobowych do systemów chmurowych firm spoza EOG może naruszać przepisy o transferze danych do krajów trzecich, co stanowi **brak zgodności z RODO**; wreszcie, dostawcy zapisują i przechowują treść zapytań użytkowników, co w przypadku danych osobowych jest niedopuszczalne.

## Obszary, w których AI może wspomóc pracę IOD

Zanim przejdziemy do rozwiązań technicznych, warto określić, w jakich konkretnie zadaniach sztuczna inteligencja może realnie pomóc IOD.

### 1. Przygotowanie i weryfikacja umów powierzenia przetwarzania danych

Przy pracy z umowami powierzenia AI może wspomóc w czterech kluczowych obszarach. Po pierwsze, umożliwia **analizę kompletności**, czyli sprawdzenie, czy umowa zawiera wszystkie wymagane elementy zgodnie z art. 28 RODO; po drugie, pozwala na **weryfikację zapisów** w celu identyfikacji niejasnych lub sprzecznych klauzul; po trzecie, może zaproponować **sugestie poprawek** zgodnych z najlepszymi praktykami; wreszcie, ułatwia **porównanie wersji** i analizę zmian między różnymi wersjami umowy.

### 2. Tworzenie i weryfikacja klauzul informacyjnych

W zakresie klauzul informacyjnych sztuczna inteligencja wspiera IOD na kilka sposobów. Przede wszystkim umożliwia **sprawdzanie kompletności**, czyli weryfikację czy klauzula zawiera wszystkie elementy wymagane przez art. 13 lub 14 RODO; następnie pozwala na **dostosowanie języka** przez uproszczenie skomplikowanych sformułowań prawnych; kolejno, ułatwia **dostosowanie do kontekstu**, czyli dopasowanie klauzuli do specyfiki danego procesu przetwarzania; w końcu, pomaga w **kontroli spójności** i weryfikacji zgodności z polityką prywatności organizacji.

### 3. Analiza i weryfikacja ocen skutków dla ochrony danych (DPIA)

Przy przeprowadzaniu ocen skutków dla ochrony danych AI może znacząco usprawnić pracę. Wspiera **identyfikację zagrożeń** przez wykrywanie potencjalnych ryzyk przetwarzania danych; umożliwia **ocenę kompletności**, czyli sprawdzenie, czy wszystkie wymagane elementy zostały uwzględnione; proponuje **sugestie środków zaradczych**, czyli działań minimalizujących ryzyko; pozwala także na **porównanie z podobnymi projektami** i odniesienie do wcześniejszych analiz.

### 4. Weryfikacja audytów wewnętrznych

W kontekście audytów wewnętrznych AI pomaga w systematycznej pracy nad wynikami kontroli. Pozwala na **analizę wyników** i identyfikację krytycznych ustaleń oraz obszarów wymagających poprawy; wspiera **priorytetyzację rekomendacji** przez ustalenie kolejności wdrażania zaleceń; ułatwia **przygotowanie planów działania** i tworzenie harmonogramów naprawczych; umożliwia również **monitorowanie postępów** w śledzeniu realizacji zaleceń pokontrolnych.

### 5. Zarządzanie wykazem osób upoważnionych

Zarządzanie upoważnieniami to kolejny obszar, w którym AI może przynieść realne korzyści. Wspomaga **weryfikację aktualności** przez identyfikację nieaktualnych upoważnień; umożliwia **kontrolę zakresu**, czyli sprawdzenie, czy zakres upoważnień odpowiada rzeczywistym potrzebom; pozwala na **wykrywanie nieprawidłowości**, szczególnie nadmiernych uprawnień; ułatwia także **przygotowanie raportów**, czyli generowanie zestawień i analiz.

### 6. Aktualizacja rejestru czynności przetwarzania

Rejestr czynności przetwarzania wymaga stałej aktualizacji, w czym AI może być cennym wsparciem. Umożliwia **wykrywanie zmian** i identyfikację nowych procesów wymagających ujęcia w rejestrze; pozwala na **weryfikację kompletności opisów**, czyli sprawdzenie, czy wszystkie wymagane elementy są wypełnione; wspiera **kontrolę spójności** przez weryfikację zgodności między różnymi zapisami; ułatwia również **generowanie raportów**, czyli tworzenie zestawień i analiz dla zarządu.

### 7. Inne typowe zadania IOD

Poza wymienionymi obszarami AI może wspomóc IOD w wielu innych codziennych zadaniach. Pomaga w **odpowiedziach na zapytania**, czyli przygotowaniu odpowiedzi na pytania pracowników dotyczące RODO; wspiera **analizę incydentów** i ocenę naruszeń ochrony danych osobowych; ułatwia **przygotowanie szkoleń** przez tworzenie materiałów edukacyjnych; wspomaga także **dokumentację procesów**, czyli opisywanie i dokumentowanie procedur.

## Rozwiązanie: Lokalne LLM jako bezpieczna alternatywa

### Czym są lokalne LLM?

Lokalne duże modele językowe to rozwiązania AI działające w całości na infrastrukturze użytkownika – na komputerze, serwerze lub we własnej chmurze organizacji. Oznacza to, że **żadne dane nie opuszczają organizacji**, co zapewnia pełną kontrolę nad przepływem informacji; następnie, **brak transmisji przez Internet** gwarantuje, że dane nie są wysyłane do zewnętrznych dostawców; dalej, **pełna prywatność** oznacza, że organizacja ma wyłączną kontrolę nad danymi; w końcu, rozwiązanie to zapewnia **zgodność z RODO** przez spełnienie wymogów dotyczących bezpieczeństwa i minimalizacji danych.

### Kluczowe narzędzia dla IOD

#### Ollama – prosty start z lokalnymi LLM

**Ollama** to narzędzie typu open-source, które umożliwia łatwe uruchamianie dużych modeli językowych lokalnie. Działa na systemach Windows, macOS i Linux. Dla IOD oferuje szereg istotnych zalet: po pierwsze, zapewnia prostą instalację jedną komendą; po drugie, daje duży wybór gotowych modeli (Llama, Mistral, Qwen, Gemma); po trzecie, umożliwia pracę offline; po czwarte, oferuje API REST umożliwiające integrację z innymi narzędziami; po piąte, nie wymaga zaawansowanej wiedzy technicznej; wreszcie, jest całkowicie bezpłatne.

**Podstawowe komendy:**
```bash
# Pobranie modelu (np. Llama 3)
ollama pull llama3

# Uruchomienie modelu
ollama run llama3

# Uruchomienie serwera API
ollama serve
```

#### LM Studio – interfejs graficzny dla mniej technicznych użytkowników

**LM Studio** to aplikacja desktopowa z przyjaznym interfejsem graficznym, idealnie nadająca się dla IOD-ów bez zaawansowanej wiedzy technicznej. Narzędzie to oferuje liczne zalety: posiada intuicyjny interfejs graficzny; umożliwia łatwą instalację modeli „klik i gotowe"; zawiera wbudowany chat podobny do ChatGPT; daje możliwość zapisywania szablonów promptów; jest dostępne na Windows, macOS i Linux; jest bezpłatne.

Typowe zastosowanie jest bardzo proste i sprowadza się do czterech kroków. Najpierw należy pobrać i zainstalować LM Studio; następnie wybrać i pobrać model z wbudowanego katalogu; kolejno skonfigurować szablon dla konkretnego zadania (np. „Jesteś ekspertem RODO weryfikującym umowy powierzenia"); w końcu można rozpocząć pracę bez konieczności używania terminala.

#### Lokalne bazy wektorowe – dla zaawansowanych zastosowań

Dla IOD-ów, którzy chcą wykorzystać AI do przeszukiwania dużej ilości dokumentów (np. wszystkich umów powierzenia, polityk prywatności, klauzul), warto rozważyć użycie lokalnych baz wektorowych. Wśród popularnych rozwiązań wyróżniają się **ChromaDB** jako najprostsze i idealne na początek; **Qdrant** jako bardzo wydajne, napisane w Rust; oraz **Weaviate** oferujące zaawansowane funkcje hybrydowego wyszukiwania.

Zastosowanie dla IOD jest szerokie i obejmuje semantyczne przeszukiwanie dokumentacji RODO; szybkie odnajdywanie podobnych klauzul w różnych umowach; analizę spójności dokumentów; a także budowanie bazy wiedzy organizacji bez wycieku danych.

### Które modele wybrać?

#### Dla zadań IOD w języku polskim:

**Llama 3.1 (8B lub 70B)**
- Bardzo dobra jakość dla języka polskiego
- Dostępny w różnych rozmiarach (8B dla średnich komputerów, 70B dla serwerów)
- Licencja open-source

**Mistral 7B**
- Dobra jakość przy małych wymaganiach sprzętowych
- Szybki w działaniu
- Świetny stosunek jakości do zasobów

**Qwen 2.5 (7B, 14B, 32B)**
- Bardzo dobre wyniki dla wielu języków, w tym polskiego
- Specjalizowane wersje (np. Qwen-Coder dla analizy skryptów)
- Zalecany przez ekspertów dla zadań wielojęzycznych

**Polskie modele:**
- **Bielik** – polski model bazujący na Mistral, dostosowany do polskiej specyfiki
- **PLLuM** – rodzina polskich modeli językowych, dostępne w różnych rozmiarach
- **Qra** – modele stworzone przez Politechnikę Gdańską, zoptymalizowane pod język polski

## Optymalny stack technologiczny dla IOD

### Konfiguracja podstawowa (dla małych organizacji lub indywidualnych IOD):

```
Komputer z co najmniej 16 GB RAM
    ↓
LM Studio lub Ollama
    ↓
Model Llama 3.1 8B lub Mistral 7B
    ↓
Lokalne przechowywanie wszystkich danych
```

### Konfiguracja zaawansowana (dla większych organizacji):

```
Serwer lokalny z 64+ GB RAM, GPU (opcjonalnie)
    ↓
Ollama jako backend
    ↓
Model Llama 3.1 70B lub Qwen 2.5 32B
    ↓
ChromaDB lub Qdrant jako baza wektorowa
    ↓
N8N do automatyzacji
    ↓
Open WebUI jako interfejs użytkownika
```

## Automatyzacja procesów IOD z N8N

### Czym jest N8N?

**N8N** to platforma automatyzacji workflow typu open-source, która umożliwia łączenie różnych aplikacji, narzędzi i lokalnych LLM w zautomatyzowane procesy biznesowe.

### Kluczowe zalety N8N dla IOD

Platforma N8N oferuje szereg istotnych zalet dla Inspektorów Ochrony Danych. Po pierwsze, zapewnia **integrację z lokalnymi LLM** przez bezpośrednie połączenie z Ollama; po drugie, daje **możliwość self-hostingu**, co oznacza pełną kontrolę nad danymi; po trzecie, oferuje **wizualny edytor**, który umożliwia tworzenie workflow bez programowania; po czwarte, zawiera **setki integracji** pozwalających na połączenie z pocztą, kalendarzem czy systemami ERP; po piąte, jest **open-source**, czyli bezpłatne z możliwością dostosowania; wreszcie, zapewnia **zgodność z RODO**, ponieważ wszystko działa lokalnie.

### Przykładowe automatyzacje dla IOD:

#### 1. Automatyczna weryfikacja umów powierzenia
```
Nowa umowa w folderze 
    → Analiza przez lokalny LLM (Ollama)
    → Sprawdzenie zgodności z szablonem
    → Wykrycie brakujących elementów
    → Wygenerowanie raportu z uwagami
    → Wysłanie emaila z wynikami
```

#### 2. Monitoring aktualności dokumentów RODO
```
Co tydzień uruchom workflow
    → Sprawdź daty ostatniej aktualizacji polityk prywatności
    → Porównaj z wymaganą częstotliwością przeglądu
    → Wygeneruj listę dokumentów wymagających aktualizacji
    → Przypomnij odpowiedzialne osoby
```

#### 3. Automatyczna odpowiedź na typowe pytania o RODO
```
Email przychodzący z pytaniem
    → Analiza treści przez lokalny LLM
    → Kategoryzacja pytania
    → Wyszukanie odpowiedzi w bazie wiedzy (ChromaDB)
    → Przygotowanie szkicu odpowiedzi
    → Wysłanie do IOD do zatwierdzenia
```

#### 4. Analiza incydentów bezpieczeństwa
```
Zgłoszenie incydentu
    → Klasyfikacja według typu i wagi (LLM)
    → Sprawdzenie wymogów notyfikacji UODO
    → Przygotowanie wstępnej dokumentacji
    → Wygenerowanie checklist działań
    → Powiadomienie odpowiednich osób
```

### Bezpieczeństwo w N8N

Przy wdrażaniu N8N dla IOD kluczowe jest zapewnienie kilku fundamentalnych elementów bezpieczeństwa. Przede wszystkim należy zadbać o **instalację on-premise**, dzięki czemu N8N działa na własnym serwerze organizacji; następnie konieczne jest **szyfrowanie danych**, aby wszystkie dane w bazie N8N były zaszyfrowane; dalej należy wdrożyć **kontrolę dostępu** w postaci RBAC (kontrola dostępu oparta na rolach); istotne są również **logi audytowe** zapewniające pełną historię wykonywanych operacji; w końcu, należy zagwarantować **brak połączeń zewnętrznych**, tak aby workflow działały wyłącznie w sieci lokalnej.

## Wymagania sprzętowe

### Komputer lokalny (dla indywidualnych IOD):

**Minimum:**
- Procesor: 4-rdzeniowy (Intel i5 / AMD Ryzen 5)
- RAM: 16 GB
- Dysk: 50 GB wolnego miejsca (SSD zalecane)
- System: Windows 10/11, macOS, Linux

**Zalecane:**
- Procesor: 8-rdzeniowy (Intel i7 / AMD Ryzen 7)
- RAM: 32 GB
- Dysk: 100 GB SSD
- GPU: NVIDIA z co najmniej 8 GB VRAM (opcjonalnie, przyspiesza działanie)

### Serwer (dla organizacji):

**Minimum:**
- Procesor: 8-rdzeniowy
- RAM: 64 GB
- Dysk: 500 GB SSD
- System: Ubuntu Server 24.04 LTS lub podobny

**Zalecane:**
- Procesor: 16+ rdzeni
- RAM: 128 GB
- GPU: NVIDIA A100 lub podobny (dla dużych modeli)
- Dysk: 1 TB NVMe SSD

## Przykładowy przepływ pracy IOD z AI

### Scenariusz: Weryfikacja nowej umowy powierzenia

Proces weryfikacji umowy z wykorzystaniem AI składa się z pięciu etapów.

W **kroku pierwszym – przygotowaniu** – IOD otrzymuje projekt umowy powierzenia od działu prawnego i zapisuje dokument lokalnie.

W **kroku drugim – wstępnej analizie** – IOD otwiera LM Studio, ładuje szablon „Weryfikacja umowy powierzenia RODO" i wkleja treść umowy. Model następnie analizuje dokument i wskazuje, czy wszystkie wymagane elementy z art. 28 RODO są obecne; identyfikuje potencjalnie problematyczne klauzule; wykrywa niejasne sformułowania.

W **kroku trzecim – szczegółowej weryfikacji** – IOD przegląda sugestie modelu, weryfikuje krytyczne uwagi i nanosi własne poprawki oparte na doświadczeniu.

W **kroku czwartym – przygotowaniu feedbacku** – IOD za pomocą AI generuje zwięzłe podsumowanie uwag, dodaje referencje do konkretnych artykułów RODO i przygotowuje propozycje poprawek.

W **kroku piątym – dokumentacji** – IOD zapisuje notatki w lokalnym systemie, dzięki czemu wszystko pozostaje w organizacji i zero danych nie wyciekło na zewnątrz.

**Oszczędność czasu:** Zamiast 2-3 godzin ręcznej analizy proces trwa jedynie 30-45 minut z weryfikacją AI.

## Dobre praktyki

### 1. Przygotowanie promptów (instrukcji dla AI)

Skuteczność AI zależy od jakości instrukcji. Dla IOD warto przygotować zestaw szablonów:

**Przykład – weryfikacja umowy:**
```
Jesteś ekspertem RODO specjalizującym się w umowach powierzenia przetwarzania danych osobowych.

Przeanalizuj poniższą umowę pod kątem zgodności z art. 28 RODO.

Sprawdź czy umowa zawiera:
1. Przedmiot i okres przetwarzania
2. Charakter i cel przetwarzania
3. Rodzaj danych osobowych i kategorie osób
4. Obowiązki i prawa administratora
5. Zobowiązania podmiotu przetwarzającego

Dla każdego elementu wskaż:
- CZY JEST: jeśli element obecny
- BRAK: jeśli element nieobecny
- UWAGA: jeśli element wymaga poprawy

Po analizie podaj konkretne rekomendacje poprawek.

[TUTAJ WKLEJ TREŚĆ UMOWY]
```

### 2. Weryfikacja wyników

Kluczowa zasada brzmi: AI jest asystentem, nie zastępstwem dla IOD. Z tego powodu należy zawsze weryfikować krytyczne wnioski; sprawdzać referencje do przepisów prawnych; nie polegać ślepo na sugestiach AI; używać własnej wiedzy i doświadczenia jako filtru.

### 3. Dokumentowanie procesu

Rzetelna dokumentacja jest niezbędna w pracy IOD. Należy zatem zapisywać, które zadania były wspierane przez AI; dokumentować, jakie modele i wersje były używane; przechowywać logi dla celów audytowych; upewnić się, że proces jest powtarzalny.

### 4. Szkolenie zespołu

Skuteczne wdrożenie AI wymaga przeszkolenia całego zespołu. Należy więc przeszkolić osoby współpracujące z IOD w zakresie używania lokalnych narzędzi AI; opracować wewnętrzne procedury korzystania z AI; regularnie aktualizować wiedzę o nowych modelach i możliwościach.

### 5. Backup i bezpieczeństwo

Bezpieczeństwo systemu wymaga systematycznego podejścia. Trzeba regularnie tworzyć kopie zapasowe modeli i konfiguracji; zabezpieczyć dostęp do narzędzi AI hasłami; monitorować wykorzystanie zasobów; aktualizować oprogramowanie.

## Aspekty prawne i compliance

### Czy korzystanie z lokalnych LLM jest zgodne z RODO?

**TAK**, pod warunkiem że spełnione są cztery fundamentalne wymagania. Po pierwsze, **dane nie opuszczają organizacji**, co oznacza, że wszystko działa lokalnie; po drugie, zapewnione są **odpowiednie zabezpieczenia techniczne**, takie jak szyfrowanie i kontrola dostępu; po trzecie, prowadzona jest **dokumentacja procesów**, czyli opisanie jak AI jest wykorzystywany; wreszcie, **rejestr czynności przetwarzania** uwzględnia wykorzystanie AI.

### Czy trzeba aktualizować umowy powierzenia?

**Zależy:**

- Jeśli IOD działa jako podmiot przetwarzający i używa lokalnych LLM w ramach wykonywania umowy – zazwyczaj **NIE**, bo dane nie są przekazywane dalej
- Jeśli organizacja zatrudnia IOD wewnętrznie – użycie lokalnych narzędzi jest częścią normalnych procesów, **NIE** wymaga osobnej regulacji

### Czy trzeba informować osoby, których dane dotyczą?

W klauzulach informacyjnych warto wskazać, że organizacja może używać narzędzi AI do zarządzania danymi osobowymi; jednocześnie nie ma obowiązku szczegółowego opisywania lokalnych narzędzi; kluczowe jest natomiast podkreślenie, że dane są przetwarzane wyłącznie wewnętrznie.

### Czy można używać AI do przetwarzania szczególnych kategorii danych?

**TAK**, w przypadku lokalnych LLM jest to możliwe, przy czym dane szczególne kategorii (zdrowotne, biometryczne, etc.) mogą być przetwarzane pod warunkiem zapewnienia odpowiednich zabezpieczeń; jednocześnie należy działać zgodnie z zasadą minimalizacji – tylko wtedy gdy jest to konieczne.

## Porównanie: komercyjne vs lokalne LLM dla IOD

| Aspekt | ChatGPT/Claude/Gemini | Lokalne LLM (Ollama/LM Studio) |
|--------|----------------------|-------------------------------|
| **Bezpieczeństwo danych** | ❌ Dane wysyłane do firm trzecich | ✅ Wszystko lokalnie |
| **Zgodność z RODO** | ❌ Problematyczna | ✅ Pełna zgodność |
| **Koszty** | 💰 Subskrypcja miesięczna | ✅ Jednorazowy zakup sprzętu |
| **Dostępność offline** | ❌ Wymaga internetu | ✅ Działa bez internetu |
| **Kontrola nad danymi** | ❌ Brak kontroli | ✅ Pełna kontrola |
| **Jakość odpowiedzi** | ⭐⭐⭐⭐⭐ Bardzo wysoka | ⭐⭐⭐⭐ Wysoka (zależna od modelu) |
| **Prędkość** | ⚡ Szybka (zależy od internetu) | ⚡ Średnia do szybkiej (zależy od sprzętu) |
| **Łatwość użycia** | ⭐⭐⭐⭐⭐ Bardzo łatwa | ⭐⭐⭐⭐ Łatwa (po instalacji) |
| **Wsparcie techniczne** | ✅ Profesjonalne | 🔶 Społeczność open-source |

## Podsumowanie

### Kluczowe wnioski

Po pierwsze, **komercyjne narzędzia AI (ChatGPT, Claude, Gemini) są nieodpowiednie dla IOD** ze względu na ryzyko wycieku danych osobowych i brak zgodności z RODO. Po drugie, **lokalne LLM to bezpieczna alternatywa**, która pozwala na wykorzystanie mocy AI bez ryzyka wycieku danych, pełną zgodność z RODO i zasadami bezpieczeństwa oraz zachowanie kontroli nad wszystkimi danymi osobowymi. Po trzecie, **narzędzia takie jak Ollama i LM Studio** umożliwiają łatwy start z lokalnymi modelami nawet dla osób bez zaawansowanej wiedzy technicznej. Po czwarte, **bazy wektorowe (ChromaDB, Qdrant)** rozszerzają możliwości lokalnych LLM o semantyczne przeszukiwanie dokumentów. Po piąte, **N8N pozwala na automatyzację** powtarzalnych procesów IOD z wykorzystaniem lokalnych LLM. Wreszcie, **modele takie jak Llama 3.1, Mistral czy Qwen** oferują wysoką jakość odpowiedzi również w języku polskim.

### Rekomendowany stack dla IOD

**Dla początkujących** zaleca się połączenie LM Studio jako interfejsu, modelu Llama 3.1 8B lub Mistral 7B oraz komputera z 16 GB RAM.

**Dla zaawansowanych** optymalnym rozwiązaniem będzie Ollama jako backend, model Llama 3.1 70B lub Qwen 2.5 32B, ChromaDB jako baza wektorowa, N8N do automatyzacji oraz serwer z 64+ GB RAM.

### Kolejne kroki

Wdrożenie lokalnych LLM w pracy IOD wymaga systematycznego podejścia. Najpierw należy **rozpocząć od instalacji LM Studio lub Ollama** na swoim komputerze; następnie **pobrać jeden z polecanych modeli** (Llama 3.1 8B to dobry start); kolejno **przetestować na prostych zadaniach**, na przykład analizie przykładowej umowy powierzenia; dalej **przygotować szablony promptów** dla typowych zadań IOD; następnie **rozważyć wdrożenie N8N** dla automatyzacji procesów; w końcu **skalować według potrzeb** przez dodanie bazy wektorowej, większych modeli oraz większej automatyzacji.

## Przydatne zasoby

### Narzędzia

Wśród kluczowych narzędzi dla IOD warto wymienić **Ollama** (<https://ollama.ai>), **LM Studio** (<https://lmstudio.ai>), **ChromaDB** (<https://www.trychroma.com>), **Qdrant** (<https://qdrant.tech>), **N8N** (<https://n8n.io>) oraz **Open WebUI** (<https://openwebui.com>).

### Modele

Polecane modele językowe obejmują **Llama 3** (<https://huggingface.co/meta-llama>), **Mistral** (<https://huggingface.co/mistralai>), **Qwen** (<https://huggingface.co/Qwen>), a także polskie modele: **Bielik** (<https://huggingface.co/speakleash/Bielik-7B-v0.1>) oraz **PLLuM** (<https://huggingface.co/collections/amu-cai/pllum>).

